{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "import sklearn\n",
    "from sklearn import cross_validation\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "from scipy import stats\n",
    "from bs4 import BeautifulSoup\n",
    "reload(sys)\n",
    "sys.setdefaultencoding(\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(raw_text):\n",
    "    review_text = BeautifulSoup(raw_text).get_text()\n",
    "    words = review_text.lower().split()\n",
    "    return(\" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeFeatureVec(words, model, num_features):\n",
    "    # Function to average all of the word vectors in a given\n",
    "    # paragraph\n",
    "    #\n",
    "    # Pre-initialize an empty numpy array (for speed)\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    #\n",
    "    nwords = 0.\n",
    "    #\n",
    "    # Index2word is a list that contains the names of the words in\n",
    "    # the model's vocabulary. Convert it to a set, for speed\n",
    "    index2word_set = set(model.index2word)\n",
    "    #\n",
    "    # Loop over each word in the review and, if it is in the model's\n",
    "    # vocaublary, add its feature vector to the total\n",
    "    \n",
    "    # wordsNotInDict is a list of words from training set that dont appear in our dictionary\n",
    "    wordsNotInDict = []\n",
    "    \n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "        else:\n",
    "            wordsNotInDict.append(word)\n",
    "    #\n",
    "    # Divide the result by the number of words to get the average\n",
    "    featureVec = np.divide(featureVec,nwords)\n",
    "    return featureVec, wordsNotInDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAvgFeatureVecs(all_texts, model, num_features):\n",
    "    # Given a set of reviews (each one a list of words), calculate\n",
    "    # the average feature vector for each one and return a 2D numpy array\n",
    "    #\n",
    "    # Initialize a counter\n",
    "    counter = 0.\n",
    "    #\n",
    "    # Preallocate a 2D numpy array, for speed\n",
    "    reviewFeatureVecs = np.zeros((len(all_texts),num_features),dtype=\"float32\")\n",
    "    #\n",
    "    \n",
    "    lineOfWordsNotInDict = []\n",
    "    # Loop through the reviews\n",
    "    for one_line in all_texts:\n",
    "       reviewFeatureVecs[counter], wordsNotInDict = makeFeatureVec(one_line, model, num_features)\n",
    "       lineOfWordsNotInDict.append(wordsNotInDict)\n",
    "       #\n",
    "       # Increment the counter\n",
    "       counter = counter + 1.\n",
    "    return reviewFeatureVecs, lineOfWordsNotInDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting a Glove Model\n",
    "model_files = [\"new.glove.twitter.27B.25d.txt\", \"new.glove.twitter.27B.50d.txt\", \n",
    "               \"new.glove.twitter.27B.100d.txt\", \"new.glove.twitter.27B.200d.txt\"]\n",
    "list_of_num_features = [25, 50, 100, 200]\n",
    "\n",
    "languages = [\"english\"]\n",
    "datafiles = [\"summary-english-truth.txt\"]\n",
    "tasks = [\"age\", \"gender\"]\n",
    "scoring_function = 'accuracy'\n",
    "all_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for model_file, num_features in zip(model_files, list_of_num_features):\n",
    "    model = gensim.models.Word2Vec.load_word2vec_format(model_file,binary=False)\n",
    "\n",
    "    for language, datafile in zip(languages, datafiles):\n",
    "        train = pd.read_csv(datafile, header=0, delimiter=\"\\t\", quoting=1)\n",
    "        num_text = train[\"text\"].size\n",
    "        clean_train_data = []\n",
    "    \n",
    "        for i in xrange( 0, num_text):\n",
    "            clean_train_data.append( clean_text( train[\"text\"][i] ) )\n",
    "        \n",
    "        trainDataVecs, trashedWords = getAvgFeatureVecs( clean_train_data, model, num_features )\n",
    "        \n",
    "        for task in tasks:\n",
    "            targetVec = train[task]\n",
    "            \n",
    "            #polynomial\n",
    "            degrees = [1,2,3]\n",
    "            C = [10**-3, 1, 10**3]\n",
    "            \n",
    "            poly_list_of_scores = []\n",
    "            for degree in degrees:\n",
    "                for one_C in C:\n",
    "                    clf = svm.SVC(kernel='poly', degree=degree, coef0=one_C, gamma=1)\n",
    "                    scores = cross_validation.cross_val_score(clf, trainDataVecs, targetVec, cv=10, scoring=scoring_function)\n",
    "                    poly_list_of_scores.append(scores)\n",
    "                    \n",
    "                    dict_key = \"dims={} task={} kernel={} degree={} C={}\".format(num_features, task, \"poly\", degree, one_C)\n",
    "                    all_results[dict_key] = scores\n",
    "            #rbf\n",
    "            gammas = [1e-5, 1e-4, 1e-3, 1, 1e3, 1e4, 1e5]\n",
    "            C = [1e-5, 1e-4, 1e-3, 1, 1e3, 1e4, 1e5]\n",
    "            \n",
    "            rbf_list_of_scores = []\n",
    "            for g in gammas:\n",
    "                for one_C in C:\n",
    "                    clf = svm.SVC(kernel='rbf', gamma=g, C=one_C)\n",
    "                    scores = cross_validation.cross_val_score(clf, trainDataVecs, targetVec, cv=10, scoring=scoring_function)\n",
    "                    rbf_list_of_scores.append(scores)\n",
    "\n",
    "                    dict_key = \"dims={} task={} kernel={} gamma={} C={}\".format(num_features, task, \"rbf\",g, one_C)\n",
    "                    all_results[dict_key] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76964285714285707"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg = []\n",
    "for one_key in all_results.keys():\n",
    "    x = all_results[one_key]\n",
    "    one_avg = x.mean()\n",
    "    avg.append(one_avg)\n",
    "a = max(avg)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAccuracies(all_results):\n",
    "    accuracies_dictionary = {}\n",
    "    for each_key in all_results.keys():\n",
    "        list_of_accuracies = all_results[each_key]\n",
    "        accuracies = list_of_accuracies.mean()\n",
    "        accuracies_dictionary[each_key] = accuracies\n",
    "    return accuracies_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracies_dictionary = getAccuracies(all_results)\n",
    "all_keys = accuracies_dictionary.keys()\n",
    "all_keys.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makePValMatrix(all_results, sorted_keys):\n",
    "    list_length = len(sorted_keys)\n",
    "    p_value_matrix = np.zeros((list_length, list_length))\n",
    "    i = range(0, list_length)\n",
    "    #sig values\n",
    "    \n",
    "    for key_1, x in zip(sorted_keys, i):\n",
    "        for key_2, y in zip(sorted_keys, i):\n",
    "            treatment_1 = all_results[key_1]\n",
    "            treatment_2 = all_results[key_2]\n",
    "            z_stat, p_val = stats.ranksums(treatment_1, treatment_2)\n",
    "            p_value_matrix[x,y] = p_val\n",
    "    return p_value_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_value_matrix = makePValMatrix(all_results, all_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = [all_results[a] for a in all_keys]\n",
    "list_of_accuracies = [a.mean() for a in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def turnPValMatrixToExcel(fileName, p_value_matrix, list_of_accuracies):\n",
    "    df = pd.DataFrame(data = p_value_matrix, columns=list_of_accuracies)\n",
    "    df.index = list_of_accuracies\n",
    "    null_disproved = df[df < 0.05]\n",
    "    null_disproved.to_csv(fileName, sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "turnPValMatrixToExcel(\"test_matrix.csv\", p_value_matrix, list_of_accuracies)\n",
    "# not such a good idea. very big matrix. compares all in computer but difficult for person to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeAvgAccuracies(fileName, accuracy_matrix, degrees, C):\n",
    "    df = pd.DataFrame(data = accuracy_matrix, columns=degrees)\n",
    "    df.index = C\n",
    "    df.to_csv(fileName, sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for num_features in list_of_num_features:\n",
    "    for task in tasks:\n",
    "        \n",
    "        kernel = \"poly\"\n",
    "        degrees = [1,2,3]\n",
    "        C = [10**-3, 1, 10**3]\n",
    "        sorted_keys = [\"dims={} task={} kernel={} degree={} C={}\".format(num_features, task, \"poly\", degree, one_C) for degree, one_C in list(itertools.product(degrees, C))]\n",
    "        sorted_keys.sort()\n",
    "        \n",
    "        p_value_matrix = makePValMatrix(all_results, sorted_keys)\n",
    "        fileName = \"avg-null-disproved-pval-dims{}-task-{}-kernel-{}.csv\".format(num_features, task, kernel)\n",
    "        list_of_accuracies = [all_results[a].mean() for a in sorted_keys]\n",
    "        turnPValMatrixToExcel(fileName, p_value_matrix, sorted_keys)\n",
    "        \n",
    "        rows = len(C)\n",
    "        cols = len(degrees)\n",
    "        accuracy_matrix = np.zeros((rows, cols))\n",
    "        \n",
    "        i = range(0, rows)\n",
    "        j = range(0, cols)\n",
    "        \n",
    "        for degree, x in zip(degrees, i):\n",
    "            for one_C, y in zip(C, j):\n",
    "                key = \"dims={} task={} kernel={} degree={} C={}\".format(num_features, task, \"poly\", degree, one_C)\n",
    "                accuracy_matrix[x, y] = all_results[key].mean()\n",
    "        \n",
    "        fileName = \"accuracy-avg-null-disproved-pval-dims{}-task-{}-kernel-{}.csv\".format(num_features, task, kernel)\n",
    "        writeAvgAccuracies(fileName, accuracy_matrix, degrees, C)\n",
    "        \n",
    "        kernel = \"rbf\"\n",
    "        gammas = [1e-5, 1e-4, 1e-3, 1, 1e3, 1e4, 1e5]\n",
    "        C = [1e-5, 1e-4, 1e-3, 1, 1e3, 1e4, 1e5]\n",
    "        \n",
    "        sorted_keys = [\"dims={} task={} kernel={} gamma={} C={}\".format(num_features, task, \"rbf\", g, one_C) for g, one_C in list(itertools.product(gammas, C))]\n",
    "        sorted_keys.sort()\n",
    "        \n",
    "        p_value_matrix = makePValMatrix(all_results, sorted_keys)\n",
    "        fileName = \"avg-null-disproved-pval-dims{}-task-{}-kernel-{}.csv\".format(num_features, task, kernel)\n",
    "        list_of_accuracies = [all_results[a].mean() for a in sorted_keys]\n",
    "        turnPValMatrixToExcel(fileName, p_value_matrix, sorted_keys)\n",
    "        \n",
    "        rows = len(C)\n",
    "        cols = len(gammas)\n",
    "        accuracy_matrix = np.zeros((rows, cols))\n",
    "        \n",
    "        i = range(0, rows)\n",
    "        j = range(0, cols)\n",
    "        \n",
    "        for g, x in zip(gammas, i):\n",
    "            for one_C, y in zip(C, j):\n",
    "                key = \"dims={} task={} kernel={} gamma={} C={}\".format(num_features, task, \"rbf\", g, one_C)\n",
    "                accuracy_matrix[x, y] = all_results[key].mean()\n",
    "        \n",
    "        fileName = \"accuracy-avg-null-disproved-pval-dims{}-task-{}-kernel-{}.csv\".format(num_features, task, kernel)\n",
    "        writeAvgAccuracies(fileName, accuracy_matrix, gammas, C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_features=25\n",
    "task=\"age\"\n",
    "kernel = \"poly\"\n",
    "degrees = [1,2,3]\n",
    "C = [10**-3, 1, 10**3]\n",
    "sorted_keys = [\"dims={} task={} kernel={} degree={} C={}\".format(num_features, task, \"poly\", degree, one_C) for degree, one_C in list(itertools.product(degrees, C))]\n",
    "sorted_keys.sort()\n",
    "        \n",
    "p_value_matrix = makePValMatrix(all_results, sorted_keys)\n",
    "fileName = \"avg-null-disproved-pval-dims{}-task-{}-kernel-{}.csv\".format(num_features, task, kernel)\n",
    "list_of_accuracies = [all_results[a].mean() for a in sorted_keys]\n",
    "turnPValMatrixToExcel(fileName, p_value_matrix, sorted_keys)\n",
    "        \n",
    "rows = len(C)\n",
    "cols = len(degrees)\n",
    "accuracy_matrix = np.zeros((rows, cols))\n",
    "        \n",
    "i = range(0, rows)\n",
    "j = range(0, cols)\n",
    "        \n",
    "for degree, x in zip(degrees, i):\n",
    "    for one_C, y in zip(C, j):\n",
    "        key = \"dims={} task={} kernel={} degree={} C={}\".format(num_features, task, \"poly\", degree, one_C)\n",
    "        accuracy_matrix[x, y] = all_results[key].mean()\n",
    "        \n",
    "fileName = \"accuracy-avg-null-disproved-pval-dims{}-task-{}-kernel-{}.csv\".format(num_features, task, kernel)\n",
    "writeAvgAccuracies(fileName, accuracy_matrix, degrees, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[list, list, int, int]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[type(degrees), type(C), type(x), type(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=range(0, 3)\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trashedWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = [\"\".join(x) for x in trashedWords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
