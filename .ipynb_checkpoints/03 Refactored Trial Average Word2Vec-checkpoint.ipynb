{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import itertools\n",
    "import sklearn\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "reload(sys)\n",
    "sys.setdefaultencoding(\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(raw_text):\n",
    "    review_text = BeautifulSoup(raw_text).get_text()\n",
    "    words = review_text.lower().split()\n",
    "    return(\" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeFeatureVec(words, model, num_features):\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    nwords = 0.\n",
    "    index2word_set = set(model.index2word)\n",
    "    wordsNotInDict = []\n",
    "    \n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "        else:\n",
    "            wordsNotInDict.append(word)\n",
    "    featureVec = np.divide(featureVec,nwords)\n",
    "    return featureVec, wordsNotInDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAvgFeatureVecs(all_texts, model, num_features):\n",
    "    counter = 0.\n",
    "    reviewFeatureVecs = np.zeros((len(all_texts),num_features),dtype=\"float32\")\n",
    "    lineOfWordsNotInDict = []\n",
    "    for one_line in all_texts:\n",
    "       reviewFeatureVecs[counter], wordsNotInDict = makeFeatureVec(one_line, model, num_features)\n",
    "       lineOfWordsNotInDict.append(wordsNotInDict)\n",
    "       counter = counter + 1.\n",
    "    return reviewFeatureVecs, lineOfWordsNotInDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting the model files: twitter-glove and wikipedia+gigaword-glove\n",
    "model_files = [ \"new.glove.twitter.27B.100d.txt\", \"new.glove.6B.100d.txt\", \n",
    "                \"new.glove.twitter.27B.200d.txt\", \"new.glove.6B.200d.txt\"]\n",
    "list_of_num_features = [100, 100, 200, 200]\n",
    "sources = [\"twitter\", \"wiki-giga\", \"twitter\", \"wiki-giga\"]\n",
    "\n",
    "languages = [\"english\"]\n",
    "datafiles = [\"summary-english-truth.txt\"]\n",
    "tasks = [\"age\", \"gender\"]\n",
    "scoring_function = 'accuracy'\n",
    "all_results = {}\n",
    "\n",
    "# poly kernel params to check\n",
    "poly_degrees = [1,2,3]\n",
    "poly_C = [10**-1, 10, 10**3]\n",
    "\n",
    "# rbf kernel params to check\n",
    "\n",
    "rbf_gammas = [1, 0.001]\n",
    "rbf_C = [10, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datafile = \"summary-english-truth.txt\"\n",
    "languages = \"english\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(datafile, header=0, delimiter=\"\\t\", quoting=1)\n",
    "num_text = train[\"text\"].size\n",
    "clean_train_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in xrange( 0, num_text):\n",
    "    clean_train_data.append( clean_text( train[\"text\"][i] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def doSVMwithPoly(trainDataVecs, targetVec, source, num_features, task, num_folds=10, degrees=[1,2,3], C=[10**-1, 10, 10**3] ):\n",
    "    poly_results = {}\n",
    "    for degree in degrees:\n",
    "        for one_C in C:\n",
    "            clf = svm.SVC(kernel='poly', degree=degree, coef0=one_C, gamma=1)\n",
    "            scores = cross_validation.cross_val_score(clf, trainDataVecs, targetVec, cv=num_folds, scoring=scoring_function)\n",
    "                    \n",
    "            dict_key = \"word2vec-source={} dims={} task={} kernel={} degree={} C={}\".format(source, num_features, task, \"poly\", degree, one_C)\n",
    "            poly_results[dict_key] = scores\n",
    "    return poly_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def doSVMwithRBF(trainDataVecs, targetVec, source, num_features, task, num_folds=10, gammas=[1, 0.001], C = [10, 1000]):\n",
    "    rbf_results = {}\n",
    "    for g in gammas:\n",
    "        for one_C in C:\n",
    "            clf = svm.SVC(kernel='rbf', gamma=g, C=one_C)\n",
    "            scores = cross_validation.cross_val_score(clf, trainDataVecs, targetVec, cv=10, scoring=scoring_function)\n",
    "            \n",
    "            dict_key = \"word2vec-source={} dims={} task={} kernel={} gamma={} C={}\".format(source, num_features, task, \"rbf\",g, one_C)\n",
    "            rbf_results[dict_key] = scores\n",
    "    return rbf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_two_dicts(x, y):\n",
    "    z = x.copy()\n",
    "    z.update(y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_results = {}\n",
    "for model_file, num_features, source in zip(model_files, list_of_num_features, sources):\n",
    "    model = gensim.models.Word2Vec.load_word2vec_format(model_file,binary=False)\n",
    "    trainDataVecs, trashedWords = getAvgFeatureVecs( clean_train_data, model, num_features )\n",
    "    \n",
    "    for task in tasks:\n",
    "        train_y = train[task]\n",
    "        poly_results = doSVMwithPoly(trainDataVecs, train_y, source, num_features, task, num_folds=10, degrees=poly_degrees, C=poly_C)\n",
    "        rbf_results = doSVMwithRBF(trainDataVecs, train_y, source, num_features, task, num_folds=10, gammas=rbf_gammas, C=rbf_C)\n",
    "        results_one_task = merge_two_dicts(poly_results, rbf_results)\n",
    "        all_results = merge_two_dicts(results_one_task, all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.625     ,  0.75      ,  0.625     ,  0.6875    ,  0.625     ,\n",
       "        0.625     ,  0.64285714,  0.92857143,  0.42857143,  0.78571429])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results['word2vec-source=wiki-giga dims=100 task=gender kernel=poly degree=3 C=1000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump( all_results, open( \"word2vec-average-d100-d200.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TO OUTPUT FILES\n",
    "# Part 1: One big excel file to do stat test between experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSortedKeys(all_results):\n",
    "    sorted_keys = all_results.keys()\n",
    "    sorted_keys.sort()\n",
    "    return sorted_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makePValMatrix(all_results):\n",
    "    sorted_keys = getSortedKeys(all_results)    \n",
    "    list_length = len(sorted_keys)\n",
    "    p_value_matrix = np.zeros((list_length, list_length))\n",
    "    i = range(0, list_length)\n",
    "    #sig values\n",
    "    \n",
    "    for key_1, x in zip(sorted_keys, i):\n",
    "        for key_2, y in zip(sorted_keys, i):\n",
    "            treatment_1 = all_results[key_1]\n",
    "            treatment_2 = all_results[key_2]\n",
    "            z_stat, p_val = stats.ranksums(treatment_1, treatment_2)\n",
    "            p_value_matrix[x,y] = p_val\n",
    "    return p_value_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def turnPValMatrixToExcel(fileName, all_results):\n",
    "    p_value_matrix = makePValMatrix(all_results)\n",
    "    sorted_keys = getSortedKeys(all_results)\n",
    "    df = pd.DataFrame(data = p_value_matrix, columns=sorted_keys)\n",
    "    df.index = sorted_keys\n",
    "    null_disproved = df[df < 0.05]\n",
    "    null_disproved.to_csv(fileName, sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "turnPValMatrixToExcel(\"all-null-disproved-p-values.csv\", all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Part 2: Make an excel file for each source, dimension, kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeAvgAccuraciesMatrixPoly(all_results, num_features, source, task, kernel, top, left):\n",
    "    if kernel == \"poly\":\n",
    "        dict_string=\"word2vec-source={} dims={} task={} kernel={} degree={} C={}\"\n",
    "    else:\n",
    "        dict_string=\"word2vec-source={} dims={} task={} kernel={} gamma={} C={}\"\n",
    "    \n",
    "    rows = len(left)\n",
    "    cols = len(top)\n",
    "    accuracy_matrix = np.zeros((rows, cols))\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            dict_name=dict_string.format(source, num_features, task, kernel, top[i],left[j])\n",
    "            accuracy_matrix[i,j] = all_results[dict_name].mean()\n",
    "            \n",
    "    filename=\"word2vec-source={} dims={} task={} kernel={}\".format(source, num_features,task, kernel)\n",
    "    return accuracy_matrix, filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeAvgAccuracies(fileName, accuracy_matrix, top, left):\n",
    "    df = pd.DataFrame(data = accuracy_matrix, columns=top)\n",
    "    df.index = left\n",
    "    df.to_csv(fileName, sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#x,y = makeAvgAccuraciesMatrixPoly(all_results, 200, \"twitter\", \"age\", \"poly\", poly_degrees, poly_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for num_features, source in zip(list_of_num_features, sources):\n",
    "    for task in tasks:\n",
    "        # do svm-poly\n",
    "        accuracy_matrix, dict_name = makeAvgAccuraciesMatrixPoly(all_results, \n",
    "                                                                 num_features,\n",
    "                                                                 source,\n",
    "                                                                 task,\n",
    "                                                                 \"poly\",\n",
    "                                                                 poly_degrees,\n",
    "                                                                 poly_C)        \n",
    "        \n",
    "        fileName=dict_name+\".csv\"\n",
    "        writeAvgAccuracies(fileName, accuracy_matrix, poly_degrees, poly_C)\n",
    "        # do svm-rbf\n",
    "        accuracy_matrix, dict_name = makeAvgAccuraciesMatrixPoly(all_results, \n",
    "                                                                 num_features,\n",
    "                                                                 source,\n",
    "                                                                 task,\n",
    "                                                                 \"rbf\",\n",
    "                                                                 rbf_gammas,\n",
    "                                                                 rbf_C)\n",
    "        fileName=dict_name+\".csv\"\n",
    "        writeAvgAccuracies(fileName, accuracy_matrix, rbf_gammas, rbf_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
